"""
PaperTrail â€” Streamlit Frontend
Beautiful, tabbed interface showcasing all agents' output.
Features: arXiv URL input, PDF upload fallback, HITL novelty review,
          Research Thread multi-paper synthesis, PDF export.
"""

import streamlit as st
from graph.pipeline import analyze_paper, analyze_pdf
from utils.pdf_report import generate_pdf_report
from agents.research_thread import ResearchThreadAgent
import streamlit.components.v1 as components
import os
import tempfile
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# â”€â”€â”€ Page Config â”€â”€â”€
st.set_page_config(
    page_title="PaperTrail â€” Research Paper Analysis",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€â”€ Custom CSS for Premium Look â”€â”€â”€
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap');
    
    .stApp { font-family: 'Inter', sans-serif; }
    
    .hero-container {
        background: linear-gradient(135deg, #1e1b4b 0%, #312e81 50%, #4338ca 100%);
        border-radius: 20px;
        padding: 40px 32px;
        margin-bottom: 24px;
        position: relative;
        overflow: hidden;
    }
    .hero-container::before {
        content: '';
        position: absolute;
        top: -50%; right: -20%;
        width: 400px; height: 400px;
        background: radial-gradient(circle, rgba(139, 92, 246, 0.3) 0%, transparent 70%);
        border-radius: 50%;
    }
    .hero-title {
        font-size: 2.5rem; font-weight: 800; color: #ffffff;
        margin: 0 0 8px 0; position: relative; z-index: 1;
    }
    .hero-subtitle {
        font-size: 1.1rem; color: #c7d2fe; margin: 0;
        position: relative; z-index: 1; font-weight: 400;
    }
    
    .paper-card {
        background: linear-gradient(135deg, #1e1b4b 0%, #312e81 100%);
        border-radius: 16px; padding: 28px; color: white; margin: 16px 0;
        border: 1px solid rgba(139, 92, 246, 0.3);
        box-shadow: 0 4px 24px rgba(0, 0, 0, 0.2);
    }
    .paper-card h2 { font-size: 1.4rem; font-weight: 700; margin-bottom: 8px; line-height: 1.3; }
    .paper-card .authors { color: #c7d2fe; font-size: 0.95rem; margin-bottom: 12px; }
    .paper-card .meta { color: #a5b4fc; font-size: 0.85rem; }
    
    .explanation-card {
        background: #f8fafc; border-left: 4px solid;
        border-radius: 0 12px 12px 0; padding: 20px; margin: 12px 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
    }
    .eli5-card { border-color: #f59e0b; background: linear-gradient(135deg, #fffbeb 0%, #fef3c7 100%); }
    .undergrad-card { border-color: #3b82f6; background: linear-gradient(135deg, #eff6ff 0%, #dbeafe 100%); }
    .expert-card { border-color: #8b5cf6; background: linear-gradient(135deg, #f5f3ff 0%, #ede9fe 100%); }
    .explanation-card h4 { margin: 0 0 12px 0; font-weight: 700; }
    .explanation-card p { margin: 0; line-height: 1.6; color: #334155; }
    
    .novelty-badge {
        display: inline-block; padding: 4px 14px; border-radius: 20px;
        font-size: 0.75rem; font-weight: 700; margin-right: 8px; letter-spacing: 0.5px;
    }
    .badge-novel { background: #dcfce7; color: #166534; }
    .badge-incremental { background: #fef3c7; color: #92400e; }
    .badge-builds { background: #e0e7ff; color: #3730a3; }
    
    .score-container {
        background: linear-gradient(135deg, #1e1b4b 0%, #312e81 100%);
        border-radius: 16px; padding: 20px 24px; text-align: center; margin: 8px 0 16px 0;
    }
    .score-number { font-size: 3rem; font-weight: 800; color: #a5b4fc; }
    .score-label { color: #c7d2fe; font-size: 0.9rem; }
    
    .insight-card {
        background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%);
        border: 1px solid #86efac; border-radius: 12px; padding: 16px 20px; margin: 12px 0;
    }
    .insight-card p { margin: 0; color: #166534; font-weight: 500; }
    
    .question-item {
        background: #f8fafc; border-radius: 10px; padding: 12px 16px;
        margin: 8px 0; border-left: 3px solid #6366f1;
    }
    
    .thread-card {
        background: linear-gradient(135deg, #fdf4ff 0%, #fae8ff 100%);
        border: 1px solid #d946ef; border-radius: 12px; padding: 20px; margin: 12px 0;
    }
    .thread-card h4 { color: #86198f; margin: 0 0 8px 0; }
    
    .hitl-box {
        background: linear-gradient(135deg, #fff7ed 0%, #ffedd5 100%);
        border: 1px solid #fb923c; border-radius: 12px; padding: 16px 20px; margin: 16px 0;
    }
    
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    .sidebar-header { font-size: 1.1rem; font-weight: 700; color: #6366f1; margin-bottom: 8px; }
</style>
""", unsafe_allow_html=True)


# â”€â”€â”€ Hero Header â”€â”€â”€
st.markdown("""
<div class="hero-container">
    <div class="hero-title">ğŸ”¬ PaperTrail</div>
    <div class="hero-subtitle">Understand any research paper in 30 seconds â€” powered by 6 AI agents</div>
</div>
""", unsafe_allow_html=True)


# â”€â”€â”€ Session State â”€â”€â”€
if "history" not in st.session_state:
    st.session_state.history = []
if "current_result" not in st.session_state:
    st.session_state.current_result = None
if "thread_result" not in st.session_state:
    st.session_state.thread_result = None


# â”€â”€â”€ Sidebar â”€â”€â”€
with st.sidebar:
    st.markdown('<div class="sidebar-header">ğŸ“š Quick Examples</div>', unsafe_allow_html=True)
    st.caption("Click to analyze a famous paper:")

    example_papers = {
        "Attention Is All You Need": "1706.03762",
        "BERT": "1810.04805",
        "GPT-3": "2005.14165",
        "ResNet": "1512.03385",
        "Diffusion Models Beat GANs": "2105.05233",
    }

    for name, arxiv_id in example_papers.items():
        if st.button(f"ğŸ“„ {name}", key=f"ex_{arxiv_id}", use_container_width=True):
            st.session_state.selected_url = f"https://arxiv.org/abs/{arxiv_id}"

    st.divider()

    # History
    if st.session_state.history:
        st.markdown('<div class="sidebar-header">ğŸ“œ Analysis History</div>', unsafe_allow_html=True)
        for i, item in enumerate(reversed(st.session_state.history)):
            if st.button(
                f"ğŸ”¬ {item['title'][:40]}...",
                key=f"hist_{i}",
                use_container_width=True,
            ):
                st.session_state.current_result = item["result"]

    st.divider()
    st.caption("Built with LangGraph, Groq, FAISS, and Streamlit")
    st.caption("ğŸ”‘ Uses Kimi K2 Instruct via Groq (free)")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INPUT SECTION â€” arXiv URL + PDF Upload Fallback
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

input_mode = st.radio(
    "Input method:",
    ["ğŸ”— arXiv URL", "ğŸ“„ Upload PDF"],
    horizontal=True,
    label_visibility="collapsed",
)

if input_mode == "ğŸ”— arXiv URL":
    col_input, col_btn = st.columns([4, 1])
    with col_input:
        default_url = st.session_state.get("selected_url", "")
        url = st.text_input(
            "Paste an arXiv URL or paper ID:",
            value=default_url,
            placeholder="https://arxiv.org/abs/1706.03762",
            label_visibility="collapsed",
        )
    with col_btn:
        analyze_clicked = st.button("ğŸ” Analyze", type="primary", use_container_width=True)

    # arXiv analysis
    if analyze_clicked and url:
        if "selected_url" in st.session_state:
            del st.session_state.selected_url

        with st.spinner("ğŸ¤– 5 AI agents analyzing your paper..."):
            try:
                result = analyze_paper(url)
                if result.get("error"):
                    st.error(f"âŒ Error: {result['error']}")
                    st.info("ğŸ’¡ If arXiv is down, try uploading the PDF directly using the 'ğŸ“„ Upload PDF' option above.")
                else:
                    st.session_state.current_result = result
                    st.session_state.history.append({
                        "title": result["parsed_paper"]["parsed"]["title"],
                        "url": url,
                        "result": result,
                    })
                    st.rerun()
            except Exception as e:
                st.error(f"âŒ An error occurred: {str(e)}")
                st.info("ğŸ’¡ Try uploading the PDF directly, or check your GROQ_API_KEY.")

else:
    # PDF Upload fallback
    st.caption("ğŸ“„ Upload any research paper PDF â€” works even when arXiv is down!")
    uploaded_file = st.file_uploader(
        "Upload a research paper PDF",
        type=["pdf"],
        label_visibility="collapsed",
    )

    if uploaded_file and st.button("ğŸ” Analyze PDF", type="primary", use_container_width=True):
        with st.spinner("ğŸ¤– 5 AI agents analyzing your uploaded paper..."):
            try:
                # Save uploaded file to temp location
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(uploaded_file.getvalue())
                    tmp_path = tmp.name

                result = analyze_pdf(tmp_path, uploaded_file.name)

                if result.get("error"):
                    st.error(f"âŒ Error: {result['error']}")
                else:
                    st.session_state.current_result = result
                    st.session_state.history.append({
                        "title": result["parsed_paper"]["parsed"]["title"],
                        "url": f"uploaded: {uploaded_file.name}",
                        "result": result,
                    })
                    st.rerun()
            except Exception as e:
                st.error(f"âŒ An error occurred: {str(e)}")
            finally:
                # Clean up temp file
                if 'tmp_path' in locals() and os.path.exists(tmp_path):
                    os.unlink(tmp_path)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DISPLAY RESULTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

result = st.session_state.current_result

if result and not result.get("error"):
    parsed = result["parsed_paper"]["parsed"]
    metadata = result["parsed_paper"]["metadata"]

    # â”€â”€â”€ Paper Info Card â”€â”€â”€
    authors_list = metadata.get("authors", ["Unknown"])
    if isinstance(authors_list, list):
        authors_str = ", ".join(authors_list[:5])
        if len(authors_list) > 5:
            authors_str += f" + {len(authors_list) - 5} more"
    else:
        authors_str = str(authors_list)

    entry_url = metadata.get("entry_url", "")
    arxiv_link = f' &nbsp;|&nbsp; ğŸ”— <a href="{entry_url}" target="_blank" style="color: #a5b4fc;">arXiv</a>' if entry_url else ""
    source_label = "ğŸ“¤ Uploaded" if metadata.get("source") == "pdf_upload" else f"ğŸ“… {metadata.get('published', 'N/A')[:10]}"

    st.markdown(f"""
    <div class="paper-card">
        <h2>{parsed['title']}</h2>
        <div class="authors">{authors_str}</div>
        <div class="meta">
            {source_label} &nbsp;|&nbsp; 
            ğŸ·ï¸ {', '.join(metadata.get('categories', ['N/A']))} &nbsp;|&nbsp; 
            ğŸ“ {parsed['paper_type'].capitalize()}{arxiv_link}
        </div>
    </div>
    """, unsafe_allow_html=True)

    # â”€â”€â”€ Tabs â”€â”€â”€
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“– Explanations",
        "ğŸ†• What's New",
        "ğŸ•¸ï¸ Concept Map",
        "â“ Questions",
        "ğŸ“¥ Export",
    ])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 1: Explanations
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab1:
        exp = result.get("explanations", {})
        if exp:
            st.markdown(f"**ğŸ’¡ In one sentence:** {exp.get('one_sentence', 'N/A')}")
            st.markdown(f"""
            <div class="insight-card">
                <p>ğŸ”‘ <strong>Key Insight:</strong> {exp.get('key_insight', 'N/A')}</p>
            </div>
            """, unsafe_allow_html=True)
            st.divider()

            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown(f"""
                <div class="explanation-card eli5-card">
                    <h4>ğŸ§’ ELI5</h4>
                    <p>{exp.get('eli5', 'N/A')}</p>
                </div>
                """, unsafe_allow_html=True)
            with col2:
                st.markdown(f"""
                <div class="explanation-card undergrad-card">
                    <h4>ğŸ“ Undergrad</h4>
                    <p>{exp.get('undergrad', 'N/A')}</p>
                </div>
                """, unsafe_allow_html=True)
            with col3:
                st.markdown(f"""
                <div class="explanation-card expert-card">
                    <h4>ğŸ”¬ Expert</h4>
                    <p>{exp.get('expert', 'N/A')}</p>
                </div>
                """, unsafe_allow_html=True)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 2: Novelty Analysis + HITL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab2:
        nov = result.get("novelty_analysis", {})
        if nov:
            # AI Score display
            ai_score = nov.get("novelty_score", 5)
            col_s1, col_s2 = st.columns([1, 3])

            with col_s1:
                st.markdown(f"""
                <div class="score-container">
                    <div class="score-number">{ai_score}/10</div>
                    <div class="score-label">AI Novelty Score</div>
                </div>
                """, unsafe_allow_html=True)

            with col_s2:
                st.markdown(f"**Summary:** {nov.get('novelty_summary', 'N/A')}")
                if ai_score >= 8:
                    st.success("ğŸŒŸ Highly novel â€” introduces significant new ideas")
                elif ai_score >= 5:
                    st.info("ğŸ“Š Solid contribution â€” meaningful improvements with some new ideas")
                else:
                    st.warning("ğŸ“ˆ Incremental â€” builds upon existing work with minor improvements")

            # â”€â”€â”€ HITL: Human-in-the-Loop Novelty Review â”€â”€â”€
            st.markdown("""
            <div class="hitl-box">
                <h4 style="color: #9a3412; margin: 0 0 4px 0;">ğŸ‘¤ Human Review (Optional)</h4>
                <p style="color: #78350f; margin: 0; font-size: 0.85rem;">
                    Disagree with the AI's assessment? Adjust the score and add your notes below.
                </p>
            </div>
            """, unsafe_allow_html=True)

            col_h1, col_h2 = st.columns([1, 3])
            with col_h1:
                human_score = st.slider(
                    "Your novelty score",
                    min_value=1, max_value=10,
                    value=ai_score,
                    key="human_novelty_score",
                )
            with col_h2:
                human_notes = st.text_area(
                    "Your review notes (optional)",
                    placeholder="e.g., 'The attention mechanism was truly novel at the time, but the architecture borrows heavily from...'",
                    height=80,
                    key="human_novelty_notes",
                )

            if human_score != ai_score:
                st.info(f"ğŸ“ Your score: **{human_score}/10** (AI said {ai_score}/10). Noted for your records.")

            st.divider()

            # Novel contributions
            st.markdown("### âœ¨ Novel Contributions")
            for c in nov.get("novel_contributions", []):
                st.markdown(f'<span class="novelty-badge badge-novel">NEW</span> {c}', unsafe_allow_html=True)

            st.markdown("### ğŸ“ˆ Incremental Improvements")
            for c in nov.get("incremental_improvements", []):
                st.markdown(f'<span class="novelty-badge badge-incremental">IMPROVED</span> {c}', unsafe_allow_html=True)

            st.markdown("### ğŸ“š Builds Upon")
            for c in nov.get("builds_upon", []):
                st.markdown(f'<span class="novelty-badge badge-builds">PRIOR</span> {c}', unsafe_allow_html=True)

            related = result.get("related_papers", [])
            if related:
                st.divider()
                st.markdown("### ğŸ”— Related Papers from Literature")
                for p in related:
                    score_val = p.get("similarity_score", 0)
                    st.markdown(f"- **{p['title']}** (similarity: `{score_val:.3f}`)")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 3: Concept Map
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab3:
        graph_path = result.get("graph_html_path")
        concept_map = result.get("concept_map", {})

        if graph_path and os.path.exists(graph_path):
            st.markdown("### ğŸ•¸ï¸ Interactive Knowledge Graph")
            st.caption("Drag nodes to rearrange â€¢ Hover for details â€¢ Scroll to zoom")

            with open(graph_path, "r", encoding="utf-8") as f:
                graph_html = f.read()
            components.html(graph_html, height=580, scrolling=True)

            st.markdown("**Legend:**")
            legend_cols = st.columns(6)
            legend_items = [
                ("ğŸ”· Method", "#6366f1"), ("ğŸŸ¡ Dataset", "#f59e0b"),
                ("ğŸŸ¢ Metric", "#10b981"), ("ğŸ”µ Concept", "#3b82f6"),
                ("ğŸ”´ Result", "#ef4444"), ("ğŸŸ£ Problem", "#8b5cf6"),
            ]
            for col, (label, color) in zip(legend_cols, legend_items):
                col.markdown(f"<span style='color:{color}'>â—</span> {label.split(' ', 1)[1]}", unsafe_allow_html=True)
        elif concept_map.get("nodes"):
            st.warning("Graph visualization file not found. Showing raw concept data:")
            st.json(concept_map)
        else:
            st.info("No concept map was generated for this paper.")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 4: Questions
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab4:
        q = result.get("questions", {})
        if q:
            st.markdown("### âœ… Questions This Paper Answers")
            for question in q.get("questions_answered", []):
                st.markdown(f'<div class="question-item">âœ… {question}</div>', unsafe_allow_html=True)

            st.markdown("### ğŸ”® Questions Left Open")
            for question in q.get("questions_left_open", []):
                st.markdown(f'<div class="question-item" style="border-color: #f59e0b;">ğŸ”® {question}</div>', unsafe_allow_html=True)

            st.markdown("### ğŸ“– Suggested Follow-Up Reading")
            for item in q.get("follow_up_reading", []):
                st.markdown(f"- ğŸ“— {item}")

            st.divider()
            st.markdown("### ğŸ’¬ Discussion Questions")
            for question in q.get("discussion_questions", []):
                st.markdown(f'<div class="question-item" style="border-color: #8b5cf6;">ğŸ’¬ {question}</div>', unsafe_allow_html=True)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 5: Export
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab5:
        st.markdown("### ğŸ“¥ Download Analysis Report")
        st.caption("Get a professional PDF report with all analysis results.")

        if st.button("ğŸ“„ Generate PDF Report", type="primary", use_container_width=True):
            with st.spinner("Generating PDF report..."):
                try:
                    pdf_path = generate_pdf_report(result)
                    with open(pdf_path, "rb") as f:
                        pdf_bytes = f.read()
                    st.download_button(
                        label="â¬‡ï¸ Download PDF",
                        data=pdf_bytes,
                        file_name=f"PaperTrail_{parsed['title'][:30].replace(' ', '_')}.pdf",
                        mime="application/pdf",
                        use_container_width=True,
                    )
                    st.success("âœ… PDF generated successfully!")
                except Exception as e:
                    st.error(f"Failed to generate PDF: {e}")

        st.divider()
        st.markdown("### ğŸ“Š Raw Analysis Data")
        with st.expander("View raw JSON output"):
            st.json(result)

elif result and result.get("error"):
    st.error(f"âŒ Analysis failed: {result['error']}")

else:
    # Empty state
    st.markdown("---")
    col_empty1, col_empty2, col_empty3 = st.columns(3)
    with col_empty1:
        st.markdown("### ğŸ“– Layered Explanations")
        st.caption("ELI5 â†’ Undergrad â†’ Expert level explanations")
    with col_empty2:
        st.markdown("### ğŸ†• Novelty Detection")
        st.caption("RAG-powered analysis of what's genuinely new")
    with col_empty3:
        st.markdown("### ğŸ•¸ï¸ Concept Maps")
        st.caption("Interactive knowledge graph visualization")
    st.markdown("---")
    st.markdown(
        "<center><p style='color: #94a3b8;'>Paste an arXiv URL or upload a PDF above to get started!</p></center>",
        unsafe_allow_html=True,
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESEARCH THREAD â€” Multi-Paper Synthesis (Agent 6)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")
st.markdown("""
<div class="thread-card">
    <h4>ğŸ§µ Research Thread â€” Multi-Paper Synthesis</h4>
    <p style="color: #86198f; margin: 0; font-size: 0.9rem;">
        Analyze 2-5 papers together to find common themes, contradictions, 
        idea evolution, and gaps for future work.
    </p>
</div>
""", unsafe_allow_html=True)

# Check if we have enough papers in history
history_papers = st.session_state.history
if len(history_papers) >= 2:
    st.caption(f"You have {len(history_papers)} papers in your history. Select 2-5 to synthesize:")

    # Paper selection checkboxes
    selected_indices = []
    for i, item in enumerate(history_papers):
        if st.checkbox(f"ğŸ“„ {item['title'][:60]}", key=f"thread_select_{i}"):
            selected_indices.append(i)

    num_selected = len(selected_indices)

    if num_selected >= 2:
        if num_selected > 5:
            st.warning("Please select at most 5 papers for synthesis.")
        else:
            if st.button(f"ğŸ§µ Synthesize {num_selected} Papers", type="primary", use_container_width=True):
                with st.spinner(f"ğŸ¤– Agent 6 synthesizing {num_selected} papers into a research thread..."):
                    try:
                        # Get parsed papers from selected history items
                        selected_papers = [
                            history_papers[i]["result"]["parsed_paper"]
                            for i in selected_indices
                        ]

                        thread_agent = ResearchThreadAgent()
                        thread_result = thread_agent.synthesize(selected_papers)
                        st.session_state.thread_result = thread_result

                    except Exception as e:
                        st.error(f"âŒ Research Thread synthesis failed: {str(e)}")

    elif num_selected == 1:
        st.info("Select at least 2 papers to generate a Research Thread.")

    # Display thread result
    thread = st.session_state.thread_result
    if thread:
        st.markdown(f"## ğŸ§µ {thread.get('thread_title', 'Research Thread')}")

        st.markdown(f"### ğŸ“ State of the Field")
        st.markdown(f"> {thread.get('field_summary', 'N/A')}")

        col_t1, col_t2 = st.columns(2)

        with col_t1:
            st.markdown("### ğŸ”— Common Themes")
            for theme in thread.get("common_themes", []):
                st.markdown(f"- ğŸ”— {theme}")

            st.markdown("### âœ… Consensus Findings")
            for finding in thread.get("consensus_findings", []):
                st.markdown(f"- âœ… {finding}")

            st.markdown("### ğŸ“ˆ Idea Evolution")
            for evolution in thread.get("idea_evolution", []):
                st.markdown(f"- ğŸ“ˆ {evolution}")

        with col_t2:
            st.markdown("### âš¡ Contradictions")
            for contradiction in thread.get("contradictions", []):
                st.markdown(f"- âš¡ {contradiction}")
            if not thread.get("contradictions"):
                st.caption("No major contradictions found.")

            st.markdown("### ğŸ”® Open Gaps")
            for gap in thread.get("open_gaps", []):
                st.markdown(f"- ğŸ”® {gap}")

            st.markdown("### ğŸš€ Recommended Next Steps")
            for step in thread.get("recommended_next_steps", []):
                st.markdown(f"- ğŸš€ {step}")

else:
    st.caption("ğŸ’¡ Analyze 2+ papers first, then select them here to generate a Research Thread synthesis.")
